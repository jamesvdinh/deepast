<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-master_plan" data-theme="dark" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Master Plan | Deep Past Challenge</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="description" content="A $1,000,000+ machine learning and computer vision competition"><meta data-rh="true" property="og:type" content="website"><meta data-rh="true" property="og:url" content="https://scrollprize.org"><meta data-rh="true" property="og:title" content="Deep Past Challenge"><meta data-rh="true" property="og:description" content="A $1,000,000+ machine learning and computer vision competition"><meta data-rh="true" property="og:image" content="https://scrollprize.org/img/social/opengraph.jpg"><meta data-rh="true" property="twitter:card" content="summary_large_image"><meta data-rh="true" property="twitter:url" content="https://scrollprize.org"><meta data-rh="true" property="twitter:title" content="Deep Past Challenge"><meta data-rh="true" property="twitter:description" content="A $1,000,000+ machine learning and computer vision competition"><meta data-rh="true" property="twitter:image" content="https://scrollprize.org/img/social/opengraph.jpg"><link data-rh="true" rel="icon" href="/deepast/img/social/favicon.ico"><link data-rh="true" rel="canonical" href="https://jamesvdinh.github.io/deepast/master_plan"><link data-rh="true" rel="alternate" href="https://jamesvdinh.github.io/deepast/master_plan" hreflang="en"><link data-rh="true" rel="alternate" href="https://jamesvdinh.github.io/deepast/master_plan" hreflang="x-default"><script src="https://cdn.usefathom.com/script.js" data-site="XERDEBQR" defer="defer" data-spa="auto"></script><link rel="stylesheet" href="/deepast/assets/css/styles.818a908c.css">
<script src="/deepast/assets/js/runtime~main.631ee407.js" defer="defer"></script>
<script src="/deepast/assets/js/main.2a1808c8.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/deepast/"><div class="navbar__logo"><img src="/deepast/img/social/favicon-64x64.png" alt="Deep Past Challenge Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/deepast/img/social/favicon-64x64.png" alt="Deep Past Challenge Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Deep Past Challenge</b></a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col"><div class="docItemContainer_Djhp"><article><div class="theme-doc-markdown markdown"><header><h1>Master Plan</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="vesuvius-challenge--stage-two">Vesuvius Challenge – Stage Two<a href="#vesuvius-challenge--stage-two" class="hash-link" aria-label="Direct link to Vesuvius Challenge – Stage Two" title="Direct link to Vesuvius Challenge – Stage Two">​</a></h2>
<ul>
<li>In 2023 Vesuvius Challenge <a href="/deepast/grandprize">made a breakthrough</a>, extracting more than four passages of never-before-seen text from inside an unopened (and unopenable) carbonized scroll. We have proven techniques for virtually unwrapping the papyrus scroll and recognizing the ink using machine learning. It wasn’t clear it was possible until we did it. This was stage one.</li>
<li>Our next step is to scale these techniques up so that we can read entire scrolls, and to figure out an efficient scanning protocol to allow us to scan and read the 300 extant scrolls, mostly in Naples. Two key technical problems need to be solved: segmentation at scale, and scanning at scale.</li>
<li>Segmentation at scale<!-- -->
<ul>
<li>The current bottleneck is tracing the papyrus surface inside the scan of the scroll (we call this “segmentation”). Currently we use manual tracing aided by various algorithms. This is quite expensive – about $100 per square centimeter. We spent about $200,000 so far to trace enough material to read the fifteen partial columns of text that were revealed in 2023.</li>
<li>Full scrolls are 10cm-20cm wide and up to 15 meters long. With current techniques it could cost $1-5 million to unwrap an entire scroll. Given that there are 300 scrolls that need to be read, it could cost hundreds of millions or even more to unwrap all of them. Clearly impractical. Also, there are parts of the scrolls that are so compressed, current techniques cannot unwrap them at all.</li>
<li>A breakthrough is needed in segmentation. So in stage two, we are going to focus on solving auto-segmentation. We believe it’s possible to bring the cost of segmenting an entire scroll to $5000 or below. It might even be possible to fully automate it.</li>
<li>Our approach to solving segmentation at scale will be to continue to leverage the community through a series of open source “progress prizes” we will award throughout the year, while hiring in full-time or part-time roles the most productive contributors to do the needed deep work. We will set as our target for 2024 to read 90% of four scrolls, and offer a $200,000 grand prize to the first team to achieve this milestone.</li>
</ul>
</li>
<li>Scanning at scale<!-- -->
<ul>
<li>Furthermore, each scan currently requires the use of a particle accelerator in England and conservator-supervised transportation of the scrolls two at a time from Naples in custom-made 3d-printed cases. This costs about $40k/scroll with current techniques, and is also subject to availability of beam time. Total cost to scan all 300 scrolls could be $30M with current techniques (at current prices).</li>
<li>A breakthrough is therefore also needed in scanning. We believe we can install one or more benchtop scanners <em>in situ</em> and scan the scrolls without removing them from the building. The benchtop sources will be slower but can run every day in parallel, probably enabling us to scan all the scrolls within a few years. We don’t know that this will work, but we suspect it will be possible to get the resolution that we need from a benchtop source. The only way to find out is to try.</li>
<li>We may also be able to devise a lower-cost scanning protocol using the particle accelerator, in the best case bringing the total cost to scan all the scrolls to $5M or below.</li>
<li>In 2024 we will explore both approaches to scanning at scale, including identifying the lowest-cost scanning protocol at the particle accelerator, negotiating for bulk rates at the particle accelerator, and testing an <em>in situ</em> scanner where the scrolls are housed. We will use full-time team members for this work.</li>
</ul>
</li>
<li>In stage 2, we plan to pursue both the segmentation and scanning breakthroughs in parallel. Along the way, we’ll work with our community to make incremental improvements to ink detection and ensure that our process works on multiple scrolls.</li>
<li>By the end of stage two, our hope is to have read at least one entire scroll, and to be ready to start stage three. We think we can do all of this in 2024.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="vesuvius-challenge--stage-three">Vesuvius Challenge – Stage Three<a href="#vesuvius-challenge--stage-three" class="hash-link" aria-label="Direct link to Vesuvius Challenge – Stage Three" title="Direct link to Vesuvius Challenge – Stage Three">​</a></h2>
<ul>
<li>Once the segmentation breakthrough and the scanning breakthrough are in place, we’ll need to systematize and staff the scanning, segmenting, and reading pipeline. The best way to do this is with a full-time team of engineers and technicians; very likely the same set of people we will be hiring for stage 2, totaling about five employees. We think this stage will take about 3 months.</li>
<li>Once the pipeline is in place, our task is to read every scroll in the collection. We expect that scanning and reading all the remaining 300 scrolls can be done in 2-3 years, depending on what we learn about the maximum speed of scanning, and depending on our ability to secure access to run the benchtop scanners, or alternatively 50-200 days of beam time at one or more appropriate particle accelerators.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="vesuvius-challenge--stage-four">Vesuvius Challenge – Stage Four<a href="#vesuvius-challenge--stage-four" class="hash-link" aria-label="Direct link to Vesuvius Challenge – Stage Four" title="Direct link to Vesuvius Challenge – Stage Four">​</a></h2>
<ul>
<li>The final stage of Vesuvius Challenge is inspiring the continued excavation of the Villa dei Papiri, and recovering in full the only surviving library from the ancient world. It is a near-certainty that there are more scrolls waiting for us in the dirt. Perhaps just a few, but there could be thousands of them.</li>
<li>Excavation is very expensive, but we expect this to be largely a political effort. Our hope is that the output of stages two and three above – previously unseen books from antiquity – will catalyze the will necessary to begin digging. If it does not, however, we will do whatever we can to make it happen.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="costs">Costs<a href="#costs" class="hash-link" aria-label="Direct link to Costs" title="Direct link to Costs">​</a></h2>
<ul>
<li>We believe Stage 2 will cost $1-2M. Thanks to a generous donation of $2,084,000 from the Musk Foundation, this stage is now fully funded, and we have a little extra money from other donations to more aggressively explore scanning at scale, and even scan some more scrolls. Our eternal gratitude to all donors!</li>
<li>If the benchtop source works, or an efficient particle accelerator protocol can be devised, we believe Stage 3 will cost $4-8M. If it doesn’t, Stage 3 will cost $15M+, depending on the cost of beam time we are able to negotiate.</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-payoff">The Payoff<a href="#the-payoff" class="hash-link" aria-label="Direct link to The Payoff" title="Direct link to The Payoff">​</a></h2>
<ul>
<li>Overfit stories of history get rewritten</li>
<li>Beautiful ancient literature is revealed</li>
<li>A new renaissance of the classics</li>
<li>Eternal glory</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/ScrollPrize/villa/tree/main/scrollprize.org/docs/27_master_plan.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Overview</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/deepast/get_started">Getting Started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Deep Past Challenge.</div></div></div></footer></div>
</body>
</html>