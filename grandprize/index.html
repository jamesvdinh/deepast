<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-grandprize" data-theme="dark" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Vesuvius Challenge 2023 Grand Prize awarded: we can read the scrolls! | Deep Past Challenge</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="description" content="The 2000-year-old scroll discusses music, food, and how to enjoy life’s pleasures."><meta data-rh="true" property="og:type" content="website"><meta data-rh="true" property="og:url" content="https://scrollprize.org/grandprize"><meta data-rh="true" property="og:title" content="Vesuvius Challenge 2023 Grand Prize awarded: we can read the scrolls!"><meta data-rh="true" property="og:description" content="The 2000-year-old scroll discusses music, food, and how to enjoy life’s pleasures."><meta data-rh="true" property="og:image" content="https://scrollprize.org/img/social/opengraph.jpg"><meta data-rh="true" property="twitter:card" content="summary_large_image"><meta data-rh="true" property="twitter:url" content="https://scrollprize.org/grandprize"><meta data-rh="true" property="twitter:title" content="Vesuvius Challenge 2023 Grand Prize awarded: we can read the scrolls!"><meta data-rh="true" property="twitter:description" content="The 2000-year-old scroll discusses music, food, and how to enjoy life’s pleasures."><meta data-rh="true" property="twitter:image" content="https://scrollprize.org/img/social/opengraph.jpg"><link data-rh="true" rel="icon" href="/img/social/favicon.ico"><link data-rh="true" rel="canonical" href="https://scrollprize.org/grandprize"><link data-rh="true" rel="alternate" href="https://scrollprize.org/grandprize" hreflang="en"><link data-rh="true" rel="alternate" href="https://scrollprize.org/grandprize" hreflang="x-default"><script src="https://cdn.usefathom.com/script.js" data-site="XERDEBQR" defer="defer" data-spa="auto"></script><link rel="stylesheet" href="/assets/css/styles.e5fc691a.css">
<script src="/assets/js/runtime~main.752a59fb.js" defer="defer"></script>
<script src="/assets/js/main.e3a6ba14.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/social/favicon-64x64.png" alt="Vesuvius Challenge Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/social/favicon-64x64.png" alt="Vesuvius Challenge Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Deep Past Challenge</b></a></div><div class="navbar__items navbar__items--right"><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1"><a class="navbar__brand custom-top-header" href="/"><div class="navbar__logo"><img src="/img/social/favicon-64x64.png" alt="Vesuvius Challenge Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Vesuvius Challenge</b></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/background">History</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/firstletters">First word discovered (Oct 2023)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/grandprize">2023 Grand Prize</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/livestream">Livestreams</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col"><div class="docItemContainer_Djhp"><article><div class="theme-doc-markdown markdown">
<h1 class="color-white text-4xl md:text-7xl font-black !mb-2 leading-none tracking-tighter">Vesuvius Challenge 2023 Grand Prize awarded: <span style="background:radial-gradient(53.44% 245.78% at 13.64% 46.56%, #F5653F 0%, #D53A17 100%);-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-clip:text;text-fill-color:transparent">we can read the first scroll!</span></h1>
<div class="md:text-2xl text-lg font-medium mt-6 mb-2 opacity-80 leading-none tracking-tight">The 2000-year-old scroll discusses music, food, and how to enjoy life’s pleasures.</div>
<div class="opacity-60 mb-8 italic">February 5th, 2024</div>
<p>We’re announcing the winners of the Vesuvius Challenge 2023 Grand Prize. We’ll look at how they did it, what the scrolls say, and what comes next.</p>
<p><em>Join us for a celebration at the Getty Villa Museum in Los Angeles on March 16th, 4pm. <a href="https://www.getty.edu/visit/cal/events/ev_4074.html">More information here</a>.</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="victory">Victory<a href="#victory" class="hash-link" aria-label="Direct link to Victory" title="Direct link to Victory">​</a></h2>
<p>Two thousand years ago, a volcanic eruption buried an ancient library of papyrus scrolls now known as the Herculaneum Papyri.</p>
<figure class=""><video autoplay="" playsinline="" loop="" muted="" class="w-[100%] sm:w-[55.6%]" poster="/img/grandprize/library-lava-small.webp"><source src="/img/grandprize/library-lava-small.webm" type="video/webm"></video><video autoplay="" playsinline="" loop="" muted="" class="hidden sm:inline sm:w-[44%]" poster="/img/grandprize/scroll-lava-small.webp"><source src="/img/grandprize/scroll-lava-small.webm" type="video/webm"></video><figcaption class="mt-0">The scrolls were <a href="https://twitter.com/natfriedman/status/1703422593670541437">carbonized</a> by the eruption of Mount Vesuvius in 79 AD.</figcaption></figure>
<p>In the 18th century the scrolls were discovered. Hundreds of them are now stored in a library in Naples, Italy; these lumps of carbonized ash cannot be opened without severely damaging them. But how can we read them if they remain rolled up?</p>
<div class="flex flex-wrap mb-4"><div class="w-[50.5%] mr-4 mb-2"><img src="/img/grandprize/scroll-1-scale.webp" class="w-[100%]"><figcaption class="mt-[-6px]">The scroll read by the winners.</figcaption></div><div class="w-[45%]"><img src="/img/grandprize/unrolled-orig.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Result of an attempt to physically unroll a scroll.</figcaption></div></div>
<p>On March 15th, 2023, Nat Friedman, Daniel Gross, and Brent Seales launched the <a href="https://scrollprize.org">Vesuvius Challenge</a> to answer this question. Scrolls from the Institut de France were imaged at the Diamond Light Source particle accelerator near Oxford. We released these high-resolution CT scans of the scrolls, and we offered more than $1M in prizes, put forward by many generous donors.</p>
<div class="flex flex-wrap mb-4"><div class="w-[41%] mr-4 mb-2"><img src="/img/grandprize/seth-diamond.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Seth Parker <a href="https://scrollprize.substack.com/p/new-scans-of-herculaneum-papyri-at">scanning</a> a scroll at the <a href="https://www.diamond.ac.uk/">Diamond Light Source</a> particle accelerator.</figcaption></div><div class="w-[54%]"><video autoplay="" playsinline="" loop="" muted="" class="w-[100%]" poster="/img/tutorials/scanning2.webp"><source src="/img/tutorials/scanning2.webm" type="video/webm"></video><figcaption class="mt-[-6px]">Artistic visualization of constructing a 3D volume.</figcaption></div></div>
<p>A global community of competitors and collaborators assembled to crack the problem with computer vision, machine learning, and hard work.</p>
<p>Less than a year later, in December 2023, they succeeded. Finally, after 275 years, we can begin to read the scrolls:</p>
<div class="mb-4"><a target="_blank" href="/img/grandprize/text_bcb-smaller.webp"><img src="/img/grandprize/text_bcb-smaller.webp" class="w-[100%]"></a><figcaption class="mt-[-6px]">Text from PHerc.Paris. 4 (Institut de France), unseen for 2,000 years. Roughly 95% of the scroll remains to be read.</figcaption></div>
<p>The thoughts of our ancestors, locked in mud and ash for 2000 years, hidden in darkness — now, with the light of a worldwide effort shining upon them, finally seen again.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="grand-prize">Grand Prize<a href="#grand-prize" class="hash-link" aria-label="Direct link to Grand Prize" title="Direct link to Grand Prize">​</a></h2>
<p>We received many excellent submissions for the Vesuvius Challenge Grand Prize, several in the final minutes before the midnight deadline on January 1st.</p>
<p>We presented these submissions to the review team, and they were met with widespread amazement. We spent the month of January carefully reviewing all submissions. Our team of eminent papyrologists worked day and night to review 15 columns of text in anonymized submissions, while the technical team audited and reproduced the submitted code and methods.</p>
<p>There was one submission that stood out clearly from the rest. Working independently, each member of our team of papyrologists recovered more text from this submission than any other. Remarkably, the entry achieved the criteria we set when announcing Vesuvius Challenge in March: 4 passages of 140 characters each, with at least 85% of characters recoverable. This was not a given: most of us on the organizing team assigned a less than 30% probability of success when we announced these criteria! And in addition, the submission includes another 11 (!) columns of text — more than 2000 characters total.</p>
<p>The results of this review were clear and unanimous: the Vesuvius Challenge Grand Prize of $700,000 is awarded to a team of three for their excellent submission. Congratulations to <strong>Youssef Nader, Luke Farritor, and Julian Schilliger</strong>!</p>
<div class="flex flex-wrap mb-4"><div class="w-[45%] sm:w-[31%] mr-4 mb-2"><img src="/img/grandprize/youssef-smaller.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Youssef Nader</figcaption></div><div class="w-[45%] sm:w-[31%] mr-4 mb-2"><img src="/img/grandprize/luke-smaller.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Luke Farritor</figcaption></div><div class="w-[45%] sm:w-[31%]"><img src="/img/grandprize/julian-smaller.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Julian Schilliger</figcaption></div></div>
<p>All three winning team members have been strong community contributors since the very beginning of Vesuvius Challenge. You may remember Youssef. He is the Egyptian PhD student in Berlin who was able to read a few columns of text back in October, winning the second-place <a href="/firstletters">First Letters Prize</a>. His results back then were particularly clear and readable, which made him the natural lead for the team that formed.</p>
<p>You might remember Luke as well: he is the 21-year-old college student and SpaceX intern from Nebraska, who was the first person in history to read an entire word from the inside of a Herculaneum scroll (ΠΟΡΦΥΡΑϹ, “purple”). This won him the first-place First Letters Prize, a few weeks before Youssef’s results.</p>
<p>And finally, you might remember Julian. He is the Swiss robotics student at ETH Zürich, who won three Segmentation Tooling prizes for his incredible work on Volume Cartographer. This enabled the 3d-mapping of the papyrus areas you see before you.</p>
<p>For the Grand Prize, they assembled into a superteam, crushing it by creating what was unanimously deemed the most readable submission.</p>
<p>The submission contains results from three different model architectures, each supporting the findings of the others, with the strongest images often coming from a <a href="https://arxiv.org/abs/2102.05095" target="_blank" rel="noopener noreferrer">TimeSformer</a>-based model. Multiple measures prevent overfitting and hallucination, including results from multiple architectures, a study across input/output window sizes, label smoothing, and varying validation folds. Like with all our prizes, this ink detection code has been made public as open source (on <a href="https://github.com/younader/Vesuvius-Grandprize-Winner" target="_blank" rel="noopener noreferrer">GitHub</a>), leveling up everyone in the community.</p>
<div class="mb-4"><a target="_blank" href="/img/grandprize/youssef_text_wbb.webp"><img src="/img/grandprize/youssef_text_wbb-smaller.webp" class="w-[100%]"></a><figcaption class="mt-[-6px]">The winners’ main submission image (TimeSformer 64x64).</figcaption></div>
<p>In addition to unparalleled ink detection, the winning submission contained the strongest auto-segmentation approach we have seen to date (more about the process of “segmentation” below). <a href="https://github.com/schillij95/ThaumatoAnakalyptor" target="_blank" rel="noopener noreferrer">ThaumatoAnakalyptor</a> (roughly: Miracle Uncoverer) by Julian generates massive papyrus segments from multiple scrolls. Re-segmentations of well known areas validate previous ink findings, and entirely new segmentations reveal writing elsewhere, such as the outermost wrap of the scroll!</p>
<div class="flex flex-wrap mb-4"><div class="w-[24%]"><img src="/img/grandprize/autoseg_paragraph_1.webp"></div><div class="w-[21%]"><img src="/img/grandprize/autoseg_paragraph_2.webp"></div><div class="w-[52%]"><img src="/img/grandprize/autoseg_paragraph_3_4.webp"></div><div class="w-[36.85%]"><img src="/img/grandprize/autoseg_outermost_sheet.webp"></div><div class="w-[30%]"><img src="/img/grandprize/autoseg_recto.webp"></div><div class="w-[30%]"><img src="/img/grandprize/autoseg_recto_64.webp"></div><figcaption class="mt-[-6px]">Outputs from auto-segmentation. The top row overlaps with the submission image, the bottom row has new segments. Much work remains to improve this promising tool.</figcaption></div>
<p>Congratulations to Youssef, Luke, and Julian. You are the well-deserved winners of the 2023 Vesuvius Challenge Grand Prize!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="runners-up">Runners up<a href="#runners-up" class="hash-link" aria-label="Direct link to Runners up" title="Direct link to Runners up">​</a></h2>
<p>Of the remaining submissions, the scores from our team of papyrologists identify a three-way tie for runner up. These entries show remarkably similar readability to each other, but still stand out from the rest by being significantly more readable. Congratulations to the following teams, each taking home $50,000!</p>
<div class="mb-4"><a target="_blank" href="/img/grandprize/sq_text_wbb.webp"><img src="/img/grandprize/sq_text_wbb-smaller.webp" class="w-[100%]"></a><figcaption class="mt-[-6px]">Shao-Qian Mah. <a href="https://github.com/SQMah/Vesuvius-Grand-Prize-Submission/">GitHub</a></figcaption></div>
<div class="mb-4"><a target="_blank" href="/img/grandprize/elian_text_wbb.webp"><img src="/img/grandprize/elian_text_wbb-smaller.webp" class="w-[100%]"></a><figcaption class="mt-[-6px]">Elian Rafael Dal Prá, Sean Johnson, Leonardo Scabini, Raí Fernando Dal Prá, João Vitor Brentigani Torezan, Daniel Baldin Franceschini, Bruno Pereira Kellm, Marcelo Soccol Gris, and Odemir Martinez Bruno. <a href="https://github.com/erdpx/vesuvius-grand-prize">GitHub</a></figcaption></div>
<div class="mb-4"><a target="_blank" href="/img/grandprize/lou_text_wbb.webp"><img src="/img/grandprize/lou_text_wbb-smaller.webp" class="w-[100%]"></a><figcaption class="mt-[-6px]">Louis Schlessinger and Arefeh Sherafati. <a href="https://github.com/lschlessinger1/vesuvius-grand-prize-submission">GitHub</a></figcaption></div>
<p>These teams each brought to the table new approaches to the subtleties of ink labeling and sampling. Be sure to check out their methods at the links above. Other teams may also now choose to share their approaches, so be sure to follow our <a href="https://discord.com/invite/uTfNwwecCQ" target="_blank" rel="noopener noreferrer">Discord community</a> for updates. Joining our community also provides access to the CT data and more images under our data agreement, as well as a front-row seat to daily discovery and collaboration!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-does-the-scroll-say">What does the scroll say?<a href="#what-does-the-scroll-say" class="hash-link" aria-label="Direct link to What does the scroll say?" title="Direct link to What does the scroll say?">​</a></h2>
<p>To date, our efforts have managed to unwrap and read about 5% of the first scroll. Our eminent team of papyrologists has been hard at work and has achieved a preliminary transcription of all the revealed columns. We now know that this scroll is not a duplicate of an existing work; it contains never-before-seen text from antiquity. The papyrology team are preparing to deliver a comprehensive study as soon as they can. You all gave them a lot of work to do! Initial readings already provide glimpses into this philosophical text. From our scholars:</p>
<div class="ml-8 mb-4">The general subject of the text is pleasure, which, properly understood, is the highest good in Epicurean philosophy. In these two snippets from two consecutive columns of the scroll, the author is concerned with whether and how the availability of goods, such as food, can affect the pleasure which they provide.</div>
<div class="ml-8 mb-4">Do things that are available in lesser quantities afford more pleasure than those available in abundance? Our author thinks not: <em>“as too in the case of food, we do not right away believe things that are scarce to be absolutely more pleasant than those which are abundant.”</em> However, is it easier for us naturally to do without things that are plentiful? <em>“Such questions will be considered frequently.”</em></div>
<div class="ml-8 mb-4">Since this is the end of a scroll, this phrasing may suggest that more is coming in subsequent books of the same work. At the beginning of the first text, a certain Xenophantus is mentioned, perhaps the same man — presumably a musician — also mentioned by Philodemus in his work <em>On Music</em>.</div>
<p><a href="https://plato.stanford.edu/entries/philodemus/" target="_blank" rel="noopener noreferrer">Philodemus</a>, of the Epicurean school, is thought to have been the philosopher-in-residence of the villa, working in the small library in which the scrolls were found.</p>
<p>Initial, rough draft transcriptions:</p>
<div class="pl-8 flex w-[100%] flex-wrap"><div class="sm:w-[48%] sm:mr-4 max-w-[300px]"><a target="_blank" href="/img/grandprize/col-8.webp"><img class="w-[100%]" src="/img/grandprize/col-8.webp"></a></div><div class="sm:w-[48%] text-[80%]"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">    col. -8, ll. 2-14:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2   ...]ι̣μ̣εν τοὺϲ̣ [πα]ρ̣[ὰ Ξ]ε̣-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    νοφάντωι το̣ιούτου[ϲ,</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ὃ καὶ ὑπ’ ἄ̣λλων δοκεῖ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">5   γείνεϲθαι, παραπλη-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ϲίωϲ δ̣’ ο̣ὐδὲ παρ̣’ ἑτέρωι</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ἴδι̣ον το̣ῦ δ̣οκοῦ̣ντοϲ̣</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    εἶναι καὶ παρὰ πλε̣ί-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    οϲ̣ι̣ν̣ ἥδιο̣ν, ἀλλ’ ὡ̣ϲ̣ καὶ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">10  ἐ̣π̣ὶ τῶν βρω̣μ̣άτ̣ων</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ο̣ὐ̣κ ἤδ̣η τὰ ϲπάνια</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    πάντωϲ̣ καὶ ἡδ̣ίω</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    τῶν δ̣αψιλῶν̣ ε̣ἶναι̣</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">14  νομίζ̣ο̣με̣ν· οὐ γ̣ὰρ̣</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div>
<div class="pl-8 flex w-[100%] flex-wrap mb-4"><div class="sm:w-[48%] sm:mr-4 max-w-[300px]"><a target="_blank" href="/img/grandprize/col-7.webp"><img class="w-[100%]" src="/img/grandprize/col-7.webp"></a></div><div class="sm:w-[48%] text-[80%]"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">    col. -7, ll. 4-10:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    λ̣ει παρὰ τὰ δαψιλῆ.</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">5   θεωρηθήϲεται δὲ τὰ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    τοιαῦθ’ οὕτω{ι} πολ̣λά-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    κιϲ πότερον ὅ̣ταν πα-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ρῇ τὸ δαψιλέϲτερον</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ἡ φύϲιϲ ἥδιον ἀπαλλάτ-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">10  τει το̣ύ̣τ̣ο̣υ̣ καὶ πάλ̣ι̣ν̣ ̣ ̣</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div>
<p>Later in the scroll:</p>
<div class="ml-8 mb-4">In the closing section of the text our author takes a parting shot at his adversaries, who <em>“have nothing to say about pleasure, either in general or in particular, when it is a question of definition.”</em></div>
<div class="pl-8 flex w-[100%] flex-wrap mb-4"><div class="sm:w-[48%] sm:mr-4 max-w-[300px]"><a target="_blank" href="/img/grandprize/col-2.webp"><img class="w-[100%]" src="/img/grandprize/col-2.webp"></a></div><div class="sm:w-[48%] text-[80%]"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">    col. -2, ll. 2-8:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">2   ἑ̣κάϲτηϲ κριτηρίων</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    θεωροῦνται. πρὸϲ δὲ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    οὔτε καθόλου περὶ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">5   ἡδονῆϲ ἐχόντων τι</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    λέγειν οὔτε περὶ τῆϲ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    κατὰ μ̣έ̣ρο̣ϲ̣, ὅ̣τε ὡ-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">8   ριϲμένον τι, ἀλλ’ οὖν</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    …</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div>
<p>Finally the scroll concludes:</p>
<div class="italic ml-8 mb-4"><em>“… for we do [not] refrain from questioning some things, but understanding/remembering others. And may it be evident to us to say true things, as they might have often appeared evident!”</em></div>
<div class="pl-8 flex w-[100%] flex-wrap"><div class="sm:w-[48%] sm:mr-4 max-w-[300px]"><a target="_blank" href="/img/grandprize/col-1.webp"><img class="w-[100%]" src="/img/grandprize/col-1.webp"></a></div><div class="sm:w-[48%] text-[80%]"><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">    col. -1, ll. 1-6:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">1   ὰρ ἀπ̣εχόμ̣ε̣θ̣α̣ τὰ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    μὲν κρίνειν, τὰ δὲ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    κατέχειν καὶ ἐμφαί</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    νoιθ’ ἡμῖν ἀληθῆ λέ-</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">5   γειν ὥϲπερ πολλά̣κιϲ</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    ἂν ἐ̣μφανε̣ίη̣{ι}.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div></div>
<p><a href="https://lsa.umich.edu/classics/people/departmental-faculty/rjanko.html" target="_blank" rel="noopener noreferrer">Richard Janko</a> writes:</p>
<div class="italic ml-8 mb-4">“Is the author Epicurus&#x27; follower, the philosopher and poet Philodemus, the teacher of Virgil? It seems very likely.</div>
<div class="italic ml-8 mb-4">Is he writing about the effect of music on the hearer, and comparing it to other pleasures like those of food and drink? Quite probably.</div>
<div class="italic ml-8 mb-4">Does this text come from his four-part treatise on music, of which we know Book 4? Quite possibly: the title should soon become available to read.</div>
<div class="italic ml-8 mb-4">Is the Xenophantus who is mentioned the celebrated flute-player, or the man famous in antiquity for being unable to control his laughter, or someone else entirely? So many questions! But improvements to the identification of the ink, which can be expected, will soon answer most of them. I can hardly wait.”</div>
<p><a href="https://www.docenti.unina.it/federica.nicolardi" target="_blank" rel="noopener noreferrer">Federica Nicolardi</a> told us:</p>
<div class="italic ml-8 mb-4">“Epicureanism says hi, with a text full of music, food, senses, and pleasure!”</div>
<p>From <a href="https://www.thebritishacademy.ac.uk/fellows/robert-fowler-FBA/" target="_blank" rel="noopener noreferrer">Bob Fowler</a>:</p>
<div class="italic ml-8 mb-4">“Like other Epicureans, he valued pleasure above all - but pleasure rightly understood, not mere indulgence. Living in ancient Rome - a society not known for abstinence - Philodemus could expect to meet with skepticism from his readers.”</div>
<p>Scholars might call it a philosophical treatise. But it seems familiar to us, and we can’t escape the feeling that the first text we’ve uncovered is a 2000-year-old blog post about how to enjoy life. Is Philodemus throwing shade at the stoics in his closing paragraph, asserting that stoicism is an incomplete philosophy because it has “nothing to say about pleasure?” The questions he seems to discuss — life’s pleasures and what makes life worth living — are still on our minds today.</p>
<p>We can expect many more works from Philodemus in the current collection, once we’re able to scale up this technique. But there could be other text as well — an Aristotle dialog, a lost history of Livy, a lost Homeric epic work, a poem from Sappho — who knows what treasures are hidden in these lumps of ash.</p>
<p>And there is the hope of a much bigger library still in the ground, since two levels of the villa remain unexcavated. More about this below!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-accurate-are-these-pictures">How accurate are these pictures?<a href="#how-accurate-are-these-pictures" class="hash-link" aria-label="Direct link to How accurate are these pictures?" title="Direct link to How accurate are these pictures?">​</a></h2>
<p>Machine learning models are infamous for “hallucinating”: making up text or pictures that look similar to their training data. Similarly, there might be ways for contestants to cheat by making up images themselves, e.g. by embedding those in the model weights. How do we know that that’s not happening here? There are a couple of answers:</p>
<ul>
<li><strong>Technical reproduction.</strong> The Vesuvius Challenge Technical Review Team reproduced the winning submissions manually. We made sure to clearly understand every part of the code, and that when we run it independently we get similar output images. Since all code and training data is now open source, you can do the same!</li>
<li><strong>Multiple submissions of the same area.</strong> You might have noticed that all submission images above show the same area of the scroll. This is because we released 3d-mapped papyrus sheets within the CT-scan (“segments”) created by our segmentation team, which were then used by all contestants. The resulting output images — created by different ML models and training labels — have produced extremely similar results. This holds not just for the winners and runner ups, but also for the other submissions that we received.</li>
<li><strong>Small input/output windows.</strong> The ink detection models are not based on Greek letters, optical character recognition (OCR), or language models. Instead, they independently detect tiny spots of ink in the CT scan, the writing appearing later when these are aggregated. As a result, the text appearing in the images is not the imagined output of a machine learning model, but is instead directly tied to the underlying data in the CT scan.</li>
</ul>
<figure><video autoplay="" playsinline="" loop="" muted="" class="w-[100%]" poster="/img/tutorials/ink-detection-anim3-dark.webp"><source src="/img/tutorials/ink-detection-anim3-dark.webm" type="video/webm"></video><figcaption class="mt-[-6px]">The models use small input/output windows. In some cases, the output is even only binary (“ink” vs “no ink”), as shown in this animation. This makes it extremely unlikely for the model to hallucinate shapes that look like letters.</figcaption></figure>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="how-does-the-unwrapping-work">How does the unwrapping work?<a href="#how-does-the-unwrapping-work" class="hash-link" aria-label="Direct link to How does the unwrapping work?" title="Direct link to How does the unwrapping work?">​</a></h2>
<div>Roughly, virtual unwrapping works in <a href="tutorial">three steps:</a></div>
<ol>
<li><strong>Scanning:</strong> creating a 3D scan of a scroll or fragment using X-ray tomography.</li>
<li><strong>Segmentation:</strong> tracing the crumpled layers of the rolled papyrus in the 3D scan and then unwrapping, or flattening, them.</li>
<li><strong>Ink Detection:</strong> identifying the inked regions in the flattened segments using a machine learning model.</li>
</ol>
<p>These scrolls were scanned at Diamond Light Source, a particle accelerator near Oxford, England. The facility produces a parallel beam of X-rays at high flux, allowing for fast, accurate, and high-resolution imaging. The X-ray photos are turned into a 3D volume of voxels using tomographic reconstruction algorithms, resulting in a stack of slice images.</p>
<figure><video autoplay="" playsinline="" loop="" muted="" class="w-[100%] max-w-[600px]" poster="/img/grandprize/.webp"><source src="/img/grandprize/scroll1.webm" type="video/webm"></video><figcaption class="mt-[-6px]">Scrubbing through the slice images of the scroll.</figcaption></figure>
<p>The next step is to identify individual sheets of papyrus in 3D space. For this we primarily use a tool called <a href="https://github.com/educelab/volume-cartographer" target="_blank" rel="noopener noreferrer">Volume Cartographer</a>, created by Seth Parker and others in Brent Seales’ lab, and augmented by our contestants, primarily Julian Schilliger (Grand Prize winner) and Philip Allgaier.</p>
<p>Volume Cartographer is operated by our team of full-time segmenters: Ben Kyles, David Josey, and Konrad Rosenberg. They use a combination of automatic algorithms and manual adjustments to map out large areas of papyrus. This is still a painstaking process, with lots of room for improvement if we’re going to segment all the scrolls.</p>
<figure><video autoplay="" playsinline="" loop="" muted="" class="max-w-[100%] rounded-xl" poster="/img/tutorials/vc-extrapolation2.webp"><source src="/img/tutorials/vc-extrapolation2.webm" type="video/webm"></video><figcaption class="mt-[-6px]">Animation showing manual and automatic segmentation in Volume Cartographer.</figcaption></figure>
<p>Finally, ink detection. Stephen Parsons at Brent’s lab had <a href="https://uknowledge.uky.edu/cs_etds/138/" target="_blank" rel="noopener noreferrer">shown</a> that Herculaneum ink could theoretically be detected in CT scans, but so far only using smaller fragments — detecting ink in the larger scans of complete scrolls had yet to be achieved. For months this part proved elusive, until progress was made on two separate tracks:</p>
<ol>
<li><strong>Crackle pattern.</strong> Last summer, Casey Handmer <a href="https://caseyhandmer.wordpress.com/2023/08/05/reading-ancient-scrolls/">discovered</a> a strange pattern of “crackle” by looking at raw flattened surface volumes. This pattern appeared to form letters. Casey won the First Ink Prize for this monumental discovery and shared it with the community, and a flurry of activity followed.</li>
</ol>
<figure class="max-w-[500px] ml-8"><img class="w-[47%] mr-4" src="/img/firstletters/pi1.webp"><img class="w-[47%]" src="/img/firstletters/pi2.webp"></figure>
<div class="ml-8 mb-4">Luke Farritor (Grand Prize winner), immediately started hunting for more crackle in flattened surface volumes produced by the segmentation team. He then trained a machine learning model on the shapes he found, which led directly to him winning the <a href="/firstletters">First Letters Prize</a> in October.</div>
<ol start="2">
<li><strong>Kaggle competition.</strong> Separately, <a href="https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection">hundreds of teams</a> tried building the best machine learning model for detecting ink in open fragments — pieces that had broken off during the physical unrolling process of scrolls, hundreds of years ago. Instead of labeling crackle (which wasn’t known yet), they had the benefit of ground truth data directly from photos of these fragments.</li>
</ol>
<div class="flex flex-wrap ml-8"><div class="sm:w-[32%] mb-2 mr-2" style="max-width:calc(33% - 8px)"><img src="/img/data/fr1.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Photo of Fragment 1</figcaption></div><div class="sm:w-[30%] mb-2 mr-2" style="max-width:calc(33% - 8px)"><img src="/img/data/ir-fr1.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Aligned infrared</figcaption></div><div class="sm:w-[30%] mb-2 mr-2" style="max-width:calc(33% - 8px)"><img src="/img/data/inklabels-fr1.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Aligned binary ink labels</figcaption></div></div>
<div class="ml-8 mb-4">This resulted in excellent models, but they did not seem to work on the flattened segments which the segmentation team produced. That was, until Youssef Nader (Grand Prize winner) used domain adaptation techniques on them, the start of a technique that ultimately won him the second place First Letters Prize.</div>
<p>After the success of the First Letters Prize, the Grand Prize seemed within reach. Youssef, Luke, and Julian teamed up, with several other teams putting in strong submissions as well.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-did-it-take">What did it take?<a href="#what-did-it-take" class="hash-link" aria-label="Direct link to What did it take?" title="Direct link to What did it take?">​</a></h2>
<p>With Vesuvius Challenge, we hope not only to solve the problem of reading the Herculaneum Papyri, but also to inspire similar projects. For that, it’s helpful to know what has contributed to our success in 2023. Here are some things we believe were important:</p>
<ol>
<li><strong>An inspiring goal and a clear target.</strong> There are many worthy causes in the world, so it helps that our goal is unusual for a computing competition. It drew more press and donations early on, it attracted an intrinsically motivated community, and it increased our probability of success to begin with (emerging research area =&gt; a higher marginal utility of dollars spent). We’d love to see more projects that are “out there,” for exactly these reasons!</li>
</ol>
<div class="mb-4 ml-8"><img src="/img/grandprize/banner.webp" class="w-[100%] max-w-[400px]"></div>
<ol start="2">
<li><strong>A solid starting point.</strong> The foundation was laid by <a href="https://www2.cs.uky.edu/dri/">Dr. Seales and his team</a>. They spent two decades making the first scroll scans, building <a href="community_projects#volume-cartographer">Volume Cartographer</a>, demonstrating the <a href="https://www2.cs.uky.edu/dri/the-scroll-from-en-gedi/">first success</a> in virtual unwrapping, and <a href="https://uknowledge.uky.edu/cs_etds/138/">proving</a> that Herculaneum ink can be detected in CT.</li>
</ol>
<div class="mb-4 ml-8"><img src="/img/landing/brent1.webp" class="w-[100%] max-w-[600px]"><figcaption class="mt-[-6px]">Brent Seales, Seth Parker, and Michael Drakopoulos at the particle accelerator.</figcaption></div>
<ol start="3">
<li><strong>Blending competition and cooperation.</strong> A Grand Prize on its own would suffer from information “hoarding”: no one would share their intermediate work, because others could take it and use it to beat them to the finish line. Without information sharing, the probability of a single team solving all the puzzle pieces to win the Grand Prize would be dramatically lower.</li>
</ol>
<div class="ml-8 mb-4">Instead, we blended competition and cooperation by adding <a href="/winners">“progress prizes”</a> along the way. These were smaller prizes (often in the $1,000-10,000 range) every ~2 months. To win a progress prize, you had to publish your code or research as open source, thereby benefiting the entire community.</div>
<div class="mb-4 ml-8"><img src="/img/grandprize/winners1.webp" class="w-[100%]"><img src="/img/grandprize/winners3.webp" class="w-[100%]"><figcaption class="mt-[-6px]">Some of the many prize winners.</figcaption></div>
<div class="ml-8 mb-4">Besides “leveling up” the entire community, this had several side benefits. We generated buzz and excitement in the community, which was motivating for everyone. It allowed winners to re-invest their winnings into better equipment, compute time, or even reduced hours at work or study to dedicate more to the competition. And it allowed people to find each other and form teams — like we saw with the Grand Prize winners.</div>
<ol start="4">
<li><strong>Hiring an in-house segmentation team.</strong> Every week we asked ourselves: what is the best thing we can do now to maximize the chance that someone wins the Grand Prize? In early summer, this led to the (then somewhat controversial) decision of hiring a full-time team of data labelers to manually trace the papyrus inside the scrolls and open source the flattened segments.</li>
</ol>
<div class="ml-8 mb-4">An alternative was to leave the problem of segmentation to the contestants, or even to award separate prizes for segments, but this had several downsides. First, it’s hard to judge segment quality before knowing what to look for (we didn’t have working ink detection yet). Incentivizing segment quantity would automatically penalize quality. Second, labeling work is tedious and time consuming, and turned out to have a long learning curve, so it’s desirable to guarantee some compensation, which can’t be done with a prize. Third, the feedback loop with prizes can be pretty long.</div>
<div class="ml-8 mb-4">We were not dogmatically attached to just being referees; we were willing to run out onto the field and kick the ball a little. So we did what we thought would maximize success, and for the critical bottleneck of segmentation, that meant hiring a team.</div>
<div class="flex flex-wrap mb-4 ml-8"><div class="w-[30%] mr-4 mb-2"><img src="/img/grandprize/ben-smaller.webp"></div><div class="w-[30%] mr-4 mb-2"><img src="/img/grandprize/david.webp"></div><div class="w-[25%]"><img src="/img/grandprize/konrad-smaller.webp"></div><figcaption class="mt-[-6px]">Our wonderful segmentation team: Ben, David, and Konrad. Also a big shout-out to former team members!</figcaption></div>
<div class="ml-8 mb-4">Ultimately, this decision worked out great. It led directly to Casey Handmer’s <a href="https://caseyhandmer.wordpress.com/2023/08/05/reading-ancient-scrolls/">discovery</a> of the “crackle pattern” — the first directly visible evidence of ink and letters within the complete scrolls. The in-house segmentation expertise also turned out to be invaluable throughout the rest of the competition, discovering areas with potentially high ink signal, and figuring out the intricacies of the structure of the scrolls. And the segmenters worked closely with community contestants, which led to much better segmentation software. It was the best of both worlds!</div>
<ol start="5">
<li><strong>Maximizing surface area for breakthroughs.</strong> Our success was the result of many smaller breakthroughs by a broad group of people. It’s remarkable how many things had to come together to make this happen. Remove any of these, and we would not have succeeded, at least not within this timeframe.</li>
</ol>
<div class="mb-4 ml-8"><img src="/img/grandprize/steps.webp" class="w-[100%] max-w-[400px]"></div>
<div class="ml-8 mb-4">There are many more contributions than we can list here - even ideas and discoveries landing outside the critical path were still important, because a massive search space had to be exhausted to find the ideas that worked. Given the right framework, the collective intelligence of a community like this is very powerful.</div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-next-announcing-the-2024-vesuvius-challenge-grand-prize">What’s next? Announcing the 2024 Vesuvius Challenge Grand Prize.<a href="#whats-next-announcing-the-2024-vesuvius-challenge-grand-prize" class="hash-link" aria-label="Direct link to What’s next? Announcing the 2024 Vesuvius Challenge Grand Prize." title="Direct link to What’s next? Announcing the 2024 Vesuvius Challenge Grand Prize.">​</a></h2>
<p>When we started the competition, most of us estimated that we had a less than 30% probability of success within the year. At that point, no letters had yet been discovered inside of a scroll. On top of that, the scrolls had barely been segmented at all. We had doubt as to whether the project could succeed, especially by the deadline we set. Was the ink signal present? Were the scans high-resolution enough? Could the techniques used to identify ink in the fragments be transferred into a scroll? None of this was known at the time. But we knew it was worth trying!</p>
<p>In Stage 1 of Vesuvius Challenge, we answered all of these questions, extracting 15 columns of never-before-seen text from inside a lump of carbon. We now have proven techniques for virtually unwrapping the papyrus scroll and recognizing ink using machine learning.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="vesuvius-challenge-stage-2">Vesuvius Challenge Stage 2<a href="#vesuvius-challenge-stage-2" class="hash-link" aria-label="Direct link to Vesuvius Challenge Stage 2" title="Direct link to Vesuvius Challenge Stage 2">​</a></h3>
<p>In 2023 we got from 0% to 5% of a scroll. In 2024 our goal is to go from 5% of one scroll, to 90% of all four scrolls we have scanned, and to lay the foundation to read all 300  scrolls.</p>
<p>The primary goal for 2024 is to read 90% of the scrolls, and <strong>we will issue the 2024 Grand Prize to the first team that is able to do this</strong>. More details on the exact grand prize judging criteria will be available in March.</p>
<p>The bottleneck to achieve this milestone is the process of tracing the surface of the papyrus inside the scroll. Today this is extremely manual. It cost us more than $100 per square centimeter in manual labor to produce the text we can read today. At this price, it would cost hundreds of millions or maybe even billions of dollars to segment all of the scrolls. While improvements to our segmentation tools have increased our efficiency, it is still far too manual and expensive. What we need is automation.</p>
<p>And so our primary goal for stage 2 is to perfect autosegmentation. Done right, this will also allow us to read the most challenging regions within the scroll – areas where the scroll was heavily compressed, cracked, delaminated, or otherwise damaged – which in many cases our current tools cannot even penetrate.</p>
<p>In 2023 we were amazed by the community contributions. We loved the competition for the grand prize, which brought out the best in the contestants, but we were also thrilled to see the community collaborate towards intermediate goals. In 2024 we are leaning into that, still offering a grand prize, but allocating even more of the prize pool towards community contributions – a pool that will grow as we raise more money.</p>
<p>We’re also planning to help speed things along ourselves, balancing prizes and in-house expertise to continue the collaboration that worked so well in 2023. To this end, we’ll hire a small software/ML team, in addition to the full-time segmentation team, who will work in the open with our community to advance the state of the art.</p>
<p>If you are interested in contributing to our funding, and joining the craziest archeological project in existence, please contact us.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="and-after-that">And after that?<a href="#and-after-that" class="hash-link" aria-label="Direct link to And after that?" title="Direct link to And after that?">​</a></h3>
<p>After that, we will scan and read every scroll. We estimate that the scrolls we have in Naples contain more than 16 megabytes of text. Some members of our papyrology team say that revealing this text will be the greatest revolution in the classics since the Renaissance. However it goes, it will certainly be fun to try!</p>
<p>And as if the prospect of reading hundreds of scrolls isn’t good enough, there might be an even bigger payoff at the end of all of this (as Nat said on the <a href="https://youtu.be/qcvMjoJdck4?t=646" target="_blank" rel="noopener noreferrer">Dwarkesh podcast</a>: <em>“there is gold in this mud”</em>).</p>
<div>Dr. Garrett Ryan (<a href="https://www.youtube.com/@toldinstone">toldinstone</a>) writes it best on our <a href="background">History page</a>:</div>
<div class="italic ml-8 mb-4">“The scrolls we have now may be just the beginning. When part of the Villa of the Papyri was cleared in the 1990s, archaeologists realized that the building was much larger than previously thought, with two unexcavated levels. At the very least, these floors likely contain more papyri in cabinets and carrying cases. And it’s probable that they conceal a far greater treasure.</div>
<div class="italic ml-8 mb-4">We have not yet found the villa’s main library, which would have contained a much wider range of Greek and Latin literature. That library, with its thousands or even tens of thousands of scrolls, must still be buried. If those texts are discovered, and if even a small fraction can still be read, they will transform our knowledge of classical life and literature on a scale not seen since the Renaissance.”</div>
<p>The potential of tens of thousands of scrolls, still buried, waiting to be discovered?! The most exciting days <a href="https://twitter.com/natfriedman/status/1712123310551548222" target="_blank" rel="noopener noreferrer">still lay ahead</a>.</p>
<p>Read more detail about what comes next in our <a href="/master_plan">Master Plan</a>.</p>
<div class="mb-4"><img src="/img/landing/rocio-espin-pinar-villa-papyri-small.webp" class="w-[100%] max-w-[600px]"></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="thank-you">Thank you<a href="#thank-you" class="hash-link" aria-label="Direct link to Thank you" title="Direct link to Thank you">​</a></h2>
<div>This couldn’t have happened without the many, many people who contributed in various ways, and we’d like to say thanks to all of them:</div>
<ul>
<li>Everyone who competed, shared insights, wrote code, made analyses, and brought energy to the project.</li>
<li>Our adventurous donors, all of whom are private individuals from the tech world, who supported this project when it was not at all clear that there was any chance of success.</li>
<li>The organizing teams (listed on our homepage): Vesuvius Challenge team, EduceLab team, and Papyrology team.</li>
<li>Our partners: EduceLab, Institut de France, Diamond Light Source, Biblioteca Nazionale di Napoli, the Getty, and Kaggle — and all their respective funders.</li>
<li>The professional and amateur papyrologists, historians, classicists, and other scholars — who helped answer countless questions in Discord.</li>
<li>The supporting staff on the Vesuvius Challenge side (Sean, Emily, Frank, Lulu), and on the University of Kentucky side (Lindsey, Eric).</li>
<li>The many contributors to the cause who came before us — who did excavations, wrote code, made scans, and built machines out of catgut and pig bladders to try to physically unroll the scrolls.</li>
<li>And of course the Grand Prize winners!</li>
</ul>
<p>Thank you all so much!!</p>
<p>Now let’s get on with it and read the rest of the scrolls. The best is yet to come.</p>
<p><em>Join us for a celebration at the Getty Villa Museum in Los Angeles on March 16th, 4pm. <a href="https://www.getty.edu/visit/cal/events/ev_4074.html">More information here</a>.</em></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/ScrollPrize/villa/tree/main/scrollprize.org/docs/26_grandprize.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/firstletters"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">First word discovered (Oct 2023)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/livestream"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Livestreams</div></a></nav></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Overview</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/get_started">Getting Started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Deep Past Challenge.</div></div></div></footer></div>
</body>
</html>