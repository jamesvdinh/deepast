"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4414],{5274:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>d,frontMatter:()=>r,metadata:()=>i,toc:()=>h});const i=JSON.parse('{"id":"community_projects","title":"Community Projects","description":"<meta","source":"@site/docs/20_community_projects.md","sourceDirName":".","slug":"/community_projects","permalink":"/community_projects","draft":false,"unlisted":false,"editUrl":"https://github.com/ScrollPrize/villa/tree/main/scrollprize.org/docs/20_community_projects.md","tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"title":"Community Projects","hide_table_of_contents":true,"hide_title":true}}');var t=s(4848),l=s(8453);const r={title:"Community Projects",hide_table_of_contents:!0,hide_title:!0},o="\ud83d\udcdc Awesome Scroll Tools Awesome",a={},h=[{value:"\ud83d\udcca Data access/visualization",id:"-data-accessvisualization",level:2},{value:"\ud83c\udf1f Highlighted",id:"-highlighted",level:3},{value:"\ud83d\udee0\ufe0f Tools",id:"\ufe0f-tools",level:3},{value:"Segmentation",id:"segmentation",level:2},{value:"\ud83c\udf1f Highlighted",id:"-highlighted-1",level:3},{value:"\ud83d\udee0\ufe0f Tools",id:"\ufe0f-tools-1",level:3},{value:"\ud83d\udce6 Materials",id:"-materials",level:3},{value:"\ud83c\udf1f Highlighted",id:"-highlighted-2",level:4},{value:"Scroll Surface Predictions",id:"scroll-surface-predictions",level:4},{value:"\ud83d\udcdc Segments",id:"-segments",level:4},{value:"\ud83c\udff7\ufe0f Volumetric Labels",id:"\ufe0f-volumetric-labels",level:4},{value:"\ud83d\udcdd Reports",id:"-reports",level:3},{value:"\ud83d\udcca Visualization",id:"-visualization",level:3},{value:"Ink Detection",id:"ink-detection",level:2},{value:"\ud83c\udfc6 3D Ink Detection",id:"-3d-ink-detection",level:3},{value:"\ud83c\udf1f Highlighted",id:"-highlighted-3",level:4},{value:"\u2699\ufe0f Tools",id:"\ufe0f-tools-2",level:4},{value:"\ud83d\udce6 Materials",id:"-materials-1",level:4},{value:"\ud83d\udd8b\ufe0f Scroll segments-based Ink Detection",id:"\ufe0f-scroll-segments-based-ink-detection",level:3},{value:"\ud83c\udf1f Highlighted",id:"-highlighted-4",level:4},{value:"\u2699\ufe0f Tools",id:"\ufe0f-tools-3",level:4},{value:"\ud83d\udce6 Materials",id:"-materials-2",level:4},{value:"\ud83d\udcdd Reports",id:"-reports-1",level:4},{value:"\ud83d\udcca Visualization",id:"-visualization-1",level:4},{value:"\ud83d\udcdc Fragment-based Ink Detection",id:"-fragment-based-ink-detection",level:3},{value:"\ud83c\udf1f Highlighted",id:"-highlighted-5",level:4},{value:"\ud83d\udcdd Reports",id:"-reports-2",level:4},{value:"Other",id:"other",level:2},{value:"\u2699\ufe0f Tools",id:"\ufe0f-tools-4",level:3},{value:"\ud83d\udce6 Materials",id:"-materials-3",level:3},{value:"\ud83d\udcdd Reports",id:"-reports-3",level:3}];function c(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",p:"p",ul:"ul",...(0,l.R)(),...e.components},{Head:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Head",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(s,{children:[(0,t.jsx)("html",{"data-theme":"dark"}),(0,t.jsx)("meta",{name:"description",content:"A $1,000,000+ machine learning and computer vision competition"}),(0,t.jsx)("meta",{property:"og:type",content:"website"}),(0,t.jsx)("meta",{property:"og:url",content:"https://scrollprize.org"}),(0,t.jsx)("meta",{property:"og:title",content:"Vesuvius Challenge"}),(0,t.jsx)("meta",{property:"og:description",content:"A $1,000,000+ machine learning and computer vision competition"}),(0,t.jsx)("meta",{property:"og:image",content:"https://scrollprize.org/img/social/opengraph.jpg"}),(0,t.jsx)("meta",{property:"twitter:card",content:"summary_large_image"}),(0,t.jsx)("meta",{property:"twitter:url",content:"https://scrollprize.org"}),(0,t.jsx)("meta",{property:"twitter:title",content:"Vesuvius Challenge"}),(0,t.jsx)("meta",{property:"twitter:description",content:"A $1,000,000+ machine learning and computer vision competition"}),(0,t.jsx)("meta",{property:"twitter:image",content:"https://scrollprize.org/img/social/opengraph.jpg"})]}),"\n",(0,t.jsx)(n.header,{children:(0,t.jsxs)(n.h1,{id:"-awesome-scroll-tools-awesome",children:["\ud83d\udcdc Awesome Scroll Tools ",(0,t.jsx)(n.a,{href:"https://awesome.re",children:(0,t.jsx)(n.img,{src:"https://awesome.re/badge.svg",alt:"Awesome"})})]})}),"\n",(0,t.jsx)(n.p,{children:"Here are all the awesome awarded open source contributions from our community that will allow us to read the scrolls! \ud83d\udcda\u2728"}),"\n",(0,t.jsxs)(n.p,{children:["Contributions are divided into four categories: ",(0,t.jsx)(n.em,{children:"Data access/visualization"}),", ",(0,t.jsx)(n.em,{children:"Segmentation"}),", ",(0,t.jsx)(n.em,{children:"Ink Detection"}),", and ",(0,t.jsx)(n.em,{children:"Other"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["Every category is subdivided in classes: \ud83c\udf1f ",(0,t.jsx)(n.em,{children:"Highlighted"})," (for popular contributions), \u2699\ufe0f ",(0,t.jsx)(n.em,{children:"Tools"}),", \ud83d\udce6 ",(0,t.jsx)(n.em,{children:"Materials"}),", \ud83d\udcdd ",(0,t.jsx)(n.em,{children:"Reports"}),", and \ud83d\udcca ",(0,t.jsx)(n.em,{children:"Visualization"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"Some highlighted contributions are added to this repository as submodules."}),"\n",(0,t.jsxs)(n.p,{children:["We keep this repository updated as much as we can, but research moves ",(0,t.jsx)(n.em,{children:"fast"}),"! \ud83c\udfc3\ud83d\udca8"]}),"\n",(0,t.jsxs)(n.p,{children:["For state-of-the-art updates join our ",(0,t.jsx)(n.a,{href:"https://discord.com/invite/uTfNwwecCQ",children:"Discord server"})," \ud83d\udcac\u23f0"]}),"\n",(0,t.jsx)(n.h2,{id:"-data-accessvisualization",children:"\ud83d\udcca Data access/visualization"}),"\n",(0,t.jsx)(n.h3,{id:"-highlighted",children:"\ud83c\udf1f Highlighted"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/scrollprize/vesuvius",children:"vesuvius"}),": Python library for accessing Vesuvius Challenge data. Allows direct access to scroll data without managing download scripts or storing terabytes of CT scans locally."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/jrudolph/vesuvius-browser",children:"Segment browser"})," is a web-based tool to browse layers and open source ink detection results of all released segments. By Johannes Rudolph"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-tools",children:"\ud83d\udee0\ufe0f Tools"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/ScrollPrize/vesuvius-c",children:"vesuvius-c"}),": C library for accessing Vesuvius Challenge data. Allows direct access to scroll data without managing download scripts or storing terabytes of CT scans locally."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/jrudolph/vesuvius-gui",children:"vesuvius-gui"})," is a single binary GUI to render volumes and segments on-the-fly. By Johannes Rudolph"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/mvrcii/phalanx",children:"vesuvius-phalanx"}),": Python library / CLI for accessing Vesuvius data. Allows flexible access to volume and fragment scroll data. By Marcel Roth"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/climbmax123/LLFIOCunkloadingTestingAndBenching",children:"llfio-chunkloader"}),": A Methode to access Data in chunks of (x,y,z) that is by lot faster and compute efficient than Zarr. (Written in C++ but it is possible to integrate in Python)."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/usc-caisplusplus/scroll-data-preprocessing",children:"preprocessed-data"}),": Data preprocessing code and a fully processed version of the dataset in .zarr format to allow for faster training of ink detection models."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"segmentation",children:"Segmentation"}),"\n",(0,t.jsx)(n.h3,{id:"-highlighted-1",children:"\ud83c\udf1f Highlighted"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/educelab/volume-cartographer",children:"Volume Cartographer"}),": the OG virtual unwrapping toolkit. Includes a graphical interface to annotate scroll segments. First built by ",(0,t.jsx)(n.a,{href:"https://educelab.engr.uky.edu/",children:"EduceLab"}),"; an ",(0,t.jsx)(n.a,{href:"https://github.com/spacegaier/volume-cartographer",children:"active fork"})," by Philip Allgaier contains many community contributions and is currently used by the segmentation team."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/KhartesViewer/khartes",children:"Khartes"})," by Chuck is a tool to manually create and visualize segment meshes, while also visualizing a preview of the rendered segment."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/ThaumatoAnakalyptor/tree/main",children:"Thaumato Anakalyptor"})," is an automatic tool that combines classical methods such as threshold gradient operator based edge detectors and Deep Learning based instance segmentation of point clouds to detect, merge and render segments. It was built by Julian Schilliger (part of Grand Prize winning submission)."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-tools-1",children:"\ud83d\udee0\ufe0f Tools"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/ThaumatoAnakalyptor/blob/main/ThaumatoAnakalyptor/sheet_to_mesh.py",children:"Fast Segment Rendering"})," by Julian Schilliger. Fast rendering of segments with GPU acceleration. Capable of saving the surface volume to multiple file formats."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/ThaumatoAnakalyptor/commit/bcd382a0ef59b2a8566ec62a474479ea9d1bb8c2",children:"CPU rendering"})," by Julian Schilliger and Giorgio Angelotti"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/JamesDarby345/Volumetric_Vesuvius_Labelling",children:"Volumetric Vesuvius Labelling"})," by James Darby. Provide custom tooling the ",(0,t.jsx)(n.a,{href:"https://napari.org/stable/",children:"napari"})," 3d viewer that will help manually annotate volumetric masks of the scrolls to train ML models for 3D segmentation."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/giorgioangel/vesuvius_autoseg_preprocess",children:"Autosegmentation preprocessing pipeline"})," (work in progress) collection of scripts to pre-process volumes for autosegmentation. By Giorgio Angelotti"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/giorgioangel/vesuvius-segment2voxel",children:"Segment2Voxel"})," by Giorgio Angelotti. Tool to create 1-voxel thick volumetric segment labels starting from mesh .obj files."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/JamesDarby345/Volumetric_Instance_to_Mesh/tree/main",children:"Volumetric Instance Labels to obj"})," by James darby. Tools to create .obj mesh files from volumetric instance labels."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/SuperOptimizer/Hraun",children:"Hraun"})," is a collection of python tools for handling volumetric scroll data by Forrest McDonald."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/OliverDaubney/vesuvius_basic_compression",children:"Scroll compression and masking"})," by Olivier Daubney. Script to compress and mask scroll data, greatly reducing storage requirements!"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/ThaumatoAnakalyptor/blob/main/ThaumatoAnakalyptor/mesh_merger.py",children:"Mesh merging"})," by Julian Schilliger. Merges multiple overlapping meshes into one continuous mesh. Flattening not included."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://gist.github.com/giorgioangel/b4cc56a5514335a2947adb058af2982b",children:"Mesh merging prototype"})," by Giorgio Angelotti. Different attempt to merge existing mesh of segments by projecting them in 2D and retriangulating in the plane."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1232307086952501313",children:"Meshing and chunking"})," by Santiago Pelufo"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tspersonalgithub/march_2024_progress_submission",children:"Volumetric segmentation model with labels"}),", deep learning 3D model to separate papyrus from air, by Tim Skinner"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1221902373887279226",children:"Superpixels and cells"})," by Santiago Pelufo"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/ThaumatoAnakalyptor/blob/main/ThaumatoAnakalyptor/slim_uv.py",children:"Segment Flattening"})," by Julian Schilliger and Giorgio Angelotti. Improved flattening of scroll segments."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/giorgioangel/slim-flatboi",children:"Slim-Flatboi"})," previous implementation of the SLIM algorithm with minimization of isometric distortion to flatten scroll segments. Later included in ThaumatoAnakalyptor. By Giorgio Angelotti."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1179216516697296906/1179216516697296906",children:"Single Sheet Segmentation attempt"})," by Brett Olsen"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/spelufo/vesuvius-blender",children:"vesuvius-blender"})," by Santiago Pelufo. Explore the X-ray scans in Blender."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/spelufo/vesuvius-build/tree/main",children:"vesuvius-build"})," by Santiago Pelufo. Scripts to build files for progressive loading of the data. Convert the tif stack to grid cells or to h5 format that can be used by Ilastik."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/MosheLevy20/VolumeAnnotate",children:"Volume Annotate"})," A partial reimplementation of Volume Cartographer in Python by Moshe Levy."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/teeohem96/VA-Sheet-Tracer",children:"VA-Sheet Tracer"})," by Trevor, Tom, Babak and Boaz"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/caethan/vesuvius_image",children:"vesuvius-image"})," by Brett Olsen. Tool for storing and viewing data, including efficient Zarr loading of stack of tif images later included in Khartes."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/educelab/quick-segment",children:"Quick Segment"})," Created by EduceLab for annotating a large air gap in Scroll 1, and then projecting from that gap to either side to create two large segments, colloquially referred to as the \u201cMonster Segment\u201d. Hasn\u2019t been used for more segmentation, since it was the only large air gap we could find."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/WillStevens/scrollreading",children:"scrollreading"})," by Will Stevens. Experiments with using algorithms based on flood-fill to extract non-intersecting surfaces from scrolls."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/hendrikschilling/volume-cartographer",children:"VC with OME-Zarr & more"})," by Hendrik Schilling:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["fast interactive OME-Zarr access and live slicing & flattening ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1286341523570688121",children:"thread"})]}),"\n",(0,t.jsxs)(n.li,{children:["instant flattening from VC segments without meshing (10s for one slice) ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1289946915269509251",children:"thread"})]}),"\n",(0,t.jsxs)(n.li,{children:["segment surface refinement (also works on obj segments) ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1290364437836075231",children:"thread"})]}),"\n",(0,t.jsxs)(n.li,{children:["fiber based segmentation efforts using an optimizing physics inspired surface meshing approach based on ceres-solver ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1301139262422646926",children:"thread"})]}),"\n",(0,t.jsxs)(n.li,{children:["non-destructive large scale interactive segment viewing and editing ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1294185795221065802",children:"thread"})]}),"\n",(0,t.jsxs)(n.li,{children:["automatic patch generation pipeline: vc_grow_seg_from_seed, vc_render_tifxyz, vc_tifxyz2obj: ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1312490723001499808",children:"thread"})]}),"\n",(0,t.jsxs)(n.li,{children:["segment tagging, segment masking, POIs, segment filters (all/filter by focus point/filter by POIs), display intersections scaling to thousands of segments ",(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1286341523570688121/1312537855846907974",children:"message"})]}),"\n",(0,t.jsxs)(n.li,{children:["low memory tiled rendering to enable GP-sized an full scroll rendering ",(0,t.jsx)(n.a,{href:"https://github.com/hendrikschilling/volume-cartographer/blob/dev-zarr/apps/src/vc_render_tifxyz.cpp",children:"https://github.com/hendrikschilling/volume-cartographer/blob/dev-zarr/apps/src/vc_render_tifxyz.cpp"})]}),"\n",(0,t.jsxs)(n.li,{children:["large segment tracing based on patch consensus: vc_grow_seg_from_segments, as documented in the ",(0,t.jsx)(n.a,{href:"https://github.com/hendrikschilling/FASP?tab=readme-ov-file#vc_grow_seg_from_segments",children:"FASP submission"})]}),"\n",(0,t.jsxs)(n.li,{children:["consistent winding number estimation by winding number diffusion: ",(0,t.jsx)(n.a,{href:"https://github.com/hendrikschilling/FASP?tab=readme-ov-file#51-winding-number-assignment",children:"vc_tifxyz_winding"})]}),"\n",(0,t.jsxs)(n.li,{children:["segment fusion & inpainting: ",(0,t.jsx)(n.a,{href:"https://github.com/hendrikschilling/FASP?tab=readme-ov-file#vc_fill_quadmesh",children:"vc_fill_quadmesh"})]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1315006782191570975",children:"fast and low memory inference for the GP ink detection"})," 1/5 the memory consumption and 20x the speed compared to the baseline GP ink detection for large segments to allow GP and full scroll size ink detection and fast preview."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/jrudolph/vesuvius-gui?tab=readme-ov-file#vesuvius-render",children:"vesuvius-render"})," by Johannes Rudolph:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Fast self-contained CPU-based rendering of segments from obj files downloading data on-the-fly."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/sgoutteb/segmata",children:"segmata"})," by Stephane Gouttebroze:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Improve the segmentation process by sharpening the layers rendering, this is based on optimizing the layer 32, a further objective is to link this optimization on a inference loop (optimizing on the detected ink instead of only layers)"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://lcparker/synthetic-pages",children:"Synthetic instance labels and volume generation"})," by lcparker"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Generate artificial 3D volumes with corresponding instance labels for use in pretraining instance segmentation networks"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://lcparker/Mask3D",children:"Mask3D for instance segmentation on scroll volumes"})," by lcparker"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"SOTA instance segmentation network, configured to work with scroll volumes"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-materials",children:"\ud83d\udce6 Materials"}),"\n",(0,t.jsx)(n.h4,{id:"-highlighted-2",children:"\ud83c\udf1f Highlighted"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/full-scrolls/Scroll1/PHercParis4.volpkg/seg-volumetric-labels/finished_cubes/",children:"Sheet instance annotation of cubes for Deep Learning models"})," (work in progress)"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/full-scrolls/Scroll1/PHercParis4.volpkg/seg-volumetric-labels/cubes/",children:"More cubes to annotate, help us!"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1249316301273436320",children:"Denoised and contrast enhanced volumes"}),", download ",(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/full-scrolls/Scroll1/PHercParis4.volpkg/volumes_denoised_ce/",children:"here"}),", same path pattern for other scrolls."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"scroll-surface-predictions",children:"Scroll Surface Predictions"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/bruniss/p2_submission/",children:"Scroll 1, and 3 Surface Predictions"})," by Sean Johnson"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/bruniss/Fiber-and-Surface-Models/Predictions/s4/",children:"Scroll 4 Surface Predictions"})," by Sean Johnson"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/bruniss/VC-Surface-Models",children:"Scroll Surface Prediction Repository and Writeup"})," by Sean Johnson"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"-segments",children:"\ud83d\udcdc Segments"}),"\n",(0,t.jsxs)(n.p,{children:["-",(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/bruniss/p2_submission/s5_initial_trace/",children:"Large Autosegmentation of Scroll5"})," by Hendrik Schilling and Sean Johnson -- Unsupervised, many switches -- check readme.md"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1079907750265499772/1245553260362858577",children:"Scroll 2 segments"})," by Sean Johnson"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1234969334535946303",children:"New segments"})," by Sean Johnson"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"http://dl.ash2txt.org/bruniss-uploads/",children:"Large segments"})," by Sean Johnson"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/jrudolph/rescaled-fragments/",children:"Rescaled to 7.91um fragment surfaces and labels"})," by Johannes Rudolph"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"\ufe0f-volumetric-labels",children:"\ud83c\udff7\ufe0f Volumetric Labels"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/JamesDarby345/Vesuvius_3D_datasets",children:"Instance segmentation labels"})," by James Darby"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-reports",children:"\ud83d\udcdd Reports"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/ThaumatoAnakalyptor/blob/main/documentation/ThaumatoAnakalyptor___Technical_Report_and_Roadmap.pdf",children:"Technical report on ThaumatoAnakalyptor"})," by Julian Schilliger"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/giorgioangel/vesuvius_autoseg_preprocess/blob/main/equalize/Scroll_Equalizer.pdf",children:"Physical equalization of scrolls' brightness"})," by Giorgio Angelotti"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://docs.google.com/document/d/1SX83Dhz5sJXHhSRbADcNxUmuH53BypLRny01rbizK8I/edit?usp=sharing",children:"Volumetric segmentation architecture investigation"})," by James Darby"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1235042673899995176/1235042673899995176",children:"Instance segmentation experiments"})," by James Darby, Ryan Reszetnik, Liamo Pennimpede, Lucas Nelson"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1177617480366170162",children:"Probabilistic view on the offset for surface volume creation"})," by Giorgio Angelotti"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://gist.github.com/jrudolph/3e0ebbd6e731f794733c236a86ff39fb",children:"Creating segments from intersecting horizontal and vertical fibers"})," by Johannes Rudolph"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-visualization",children:"\ud83d\udcca Visualization"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1246129199304151052/1246129199304151052",children:"Browser-based scroll viewer"})," by Yao Hsiao"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tomhsiao1260/wj-wt-ftt",children:"wj-wt-ftt"})," by Yao Hsiao and Dalufishe. Tool to view and annotate volumetric scrolls data."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/Crackle-Viewer",children:"Crackle Viewer"})," is a tool to browse and annotate surface volumes of rendered segments, by Julian Schilliger"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/giorgioangel/vesuvius-compare/",children:"Point cloud extraction method comparer"})," by Giorgio Angelotti. Tool to compare different point cloud extraction methods."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tomhsiao1260/pipeline-visualize",children:"Pipeline Visualize"})," by Yao Hsiao. Tool to visualize the first steps of the Thaumato Anakalyptor pipeline."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1162822294415097907/threads/1167722091781554290",children:"Cell viewer and segmentation comparison"})," by Yao Hsiao"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tomhsiao1260/vc-whiteboard/tree/demo-3",children:"Volume Viewer"})," Used by the segmentation team primarily to see which segments they have worked on already. Hosted ",(0,t.jsx)(n.a,{href:"http://37.19.207.113:5174/",children:"here"}),". By Yao Hsiao"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tomhsiao1260/vc-whiteboard/tree/dev",children:"Vesuvius Challenge Whiteboard"})," by Yao Hsiao and Dalufishe"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tomhsiao1260/neuroglancer-mini",children:"Neuroglancer Mini"})," A trimmed-down version of the Neuroglancer source code. By Yao Hsiao"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/lukeboi/scroll-viewer",children:"Scroll Viewer"})," by Luke Farritor. A lightweight, extensible tool for viewing volumetric data, which runs in the browser, and is very fast."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/Paul-G2/ScrollSleuth",children:"Scroll Sleuth"})," by Paul Geiger. A web app that supports visual ink-searching in segment volumes via multiple display modes and segmentation tools."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"ink-detection",children:"Ink Detection"}),"\n",(0,t.jsx)(n.h3,{id:"-3d-ink-detection",children:"\ud83c\udfc6 3D Ink Detection"}),"\n",(0,t.jsx)(n.h4,{id:"-highlighted-3",children:"\ud83c\udf1f Highlighted"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/ryanchesler/3d-ink-detection",children:"3D (volumetric) Ink detection model"})," by Ryan Chesler. Ink detection model that works on full scroll data in 3D, without segmentation nor flattening."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/bruniss/3d%20Ink%20/",children:"Volumetric Ink Detection for Scroll 1, 2, 3, 4"})," by Sean Johnson"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"\ufe0f-tools-2",children:"\u2699\ufe0f Tools"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/ryanchesler/LSM/blob/main/README.md",children:"Large Scroll Model"})," is a 3D Unet pretrained on scroll data, by Ryan Chesler"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://gist.github.com/giorgioangel/6ae26b126f364dda751a10be0b90b36d",children:"UV predictions visualizer"})," by Giorgio Angelotti. Script to quickly visualize the ink predictions output by Ryan Chesler's 3D model as a scatter pkot on segments. Needs the predictions Zarr for the full scroll."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1204133327083147264",children:"Volumetric ink detection attempt"})," by Jorge Villaescusa"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/younader/Inkalyzer",children:"Inkalyzer"})," by Youssef Nader. XAI package for Ink models to explain predictions and generate volumetric labels."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"-materials-1",children:"\ud83d\udce6 Materials"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1079907750265499772/1223357870762889308",children:"3D Ink labels"})," by Sean Johnsonn"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/ryan/",children:"3D Ink predictions"})," by Ryan Chesler. Predictions of 3D Ink models on full scrolls in Zarr format."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-scroll-segments-based-ink-detection",children:"\ud83d\udd8b\ufe0f Scroll segments-based Ink Detection"}),"\n",(0,t.jsx)(n.h4,{id:"-highlighted-4",children:"\ud83c\udf1f Highlighted"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/younader/Vesuvius-Grandprize-Winner",children:"Grand Prize Winner Ink Detection model"})," by Youssef Nader, Luke Farritor and Julian Schilliger"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"\ufe0f-tools-3",children:"\u2699\ufe0f Tools"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/jgcarrasco/ScrollMAE",children:"ScrollMAE"})," by Jorge Garc\xeda. Contains the necessary code to pretrain a 3D ResNet on unlabeled data and then finetune it to perform ink detection."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/jgcarrasco/dino-ink-detection",children:"Unsupervised Ink Detection with DINO"})," by Jorge Garc\xeda. Contains experiments related to detecting ink without labels, including a Colab notebook."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/jaredlandau/Vesuvius-Grandprize-Winner-Plus",children:"Vesuvius GP+"})," by Jared Landau. Updated version of the Grand Prize Ink Detection script with extra features."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/OliverDaubney/s2slabmap",children:"Segment-to-segment label mapping"})," by Oliver Daubney"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Runner Up Models, December, 2023"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/SQMah/Vesuvius-Grand-Prize-Submission/",children:"Ink detection model"})," by SQ Mah"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/lschlessinger1/vesuvius-grand-prize-submission",children:"Ink detection model"})," by Lou Schlessinger and Arefeh Sherafati"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/erdpx/vesuvius-grand-prize",children:"Ink detection model"})," by lian Rafael Dal Pr\xe1, Sean Johnson, Leonardo Scabini, Ra\xed Fernando Dal Pr\xe1, Jo\xe3o Vitor Brentigani Torezan, Daniel Baldin Franceschini, Bruno Pereira Kellm, Marcelo Soccol Gris, Odemir Martinez Bruno"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/giorgioangel/vesuvius-kintsugi",children:"Vesuvius Kintsugi"})," is a tool to label floodfill surface volumes of rendered segments, by Giorgio Angelotti"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://onedrive.live.com/?authkey=%21ALfVTOHQOkbecQ0&id=D6F698278C30CB3E%212310&cid=D6F698278C30CB3E",children:"Omit"})," is a pipeline that tries to detect ink with classical approaches (not deep learning) by Timo Meireman"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"First Letters winning models, October 2023"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/lukeboi/scroll-first-letters",children:"Ink detection model"})," by Luke Farritor"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/younader/Vesuvius-First-Letters",children:"Ink detection model, 2nd place but more accurate"})," by Youssef Nader"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/schillij95/Crackle-Viewer",children:"Crackle Viewer"})," is a tool to browse and annotate surface volumes of rendered segments, by Julian Schilliger"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/lukeboi/scroll-fourth-second/blob/master/README.md",children:"Fourth placed Kaggle model finetuning"})," on scroll data by Luke Farritor"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/younader/VesuviusPretraining",children:"Scroll pretraining"})," by Youssef Nader. Youssef\u2019s original idea for pretraining on the scrolls and finetuning on the fragments, which led him to winning the First Letters Prize."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/SergeyPnev/dinov2-vesuvius",children:"pre-trained DINOv2 models"})," by Sergei Pnev. Self-supervised model pre-trained on scrolls 1-5 with predictions."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"-materials-2",children:"\ud83d\udce6 Materials"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1223849912467460116",children:"Scroll 1 Ink Labels"}),". Nicola Bodill produced more accurate labels for ink detection based on the prediction of the Grand Prize winner model"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/luke/youssef_uploads/scroll_4/",children:"Scroll 4 predictions"}),". Youssef Nader produced some predictions on Scroll 4 from his Grand prize winner model. No sure trace of ink yet"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1177039383375912990/1177039383375912990",children:"Ink detection masks"}),". Anton Repushko shared some ink labels for Scroll 1, these labels were used by many participants for their final submission in December 2023."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/bruniss/",children:"Crackle labels on Scroll 1"})," by Sean Johnson"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["[Ink Generator]\n(",(0,t.jsx)(n.a,{href:"https://github.com/StewartSethA/VesuviusInkGenerator",children:"https://github.com/StewartSethA/VesuviusInkGenerator"}),") by Seth Stewart, ink volume sample patches generated using gradient ascent"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/Bodillium/Herculaneum-Scroll-Labels",children:"Scroll 5 Ink Labels"})," by Nicola Bodill. Early ink labels for Scroll 5."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"-reports-1",children:"\ud83d\udcdd Reports"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://medium.com/@jaredlandau/vesuvius-challenge-ink-detection-part-1-introduction-1cb125a56b21",children:"Introduction to Ink Detection"})," by Jared Landau"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://www.youtube.com/watch?v=F5ak1pRaqVo&ab_channel=VesuviusChallenge",children:"Grand Prize Presentation"})," by Youssef Nader and Julian Schilliger"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://caseyhandmer.wordpress.com/2023/08/05/reading-ancient-scrolls/",children:"First Ink on scroll 1"})," by Casey Handmer"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"-visualization-1",children:"\ud83d\udcca Visualization"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://github.com/tomhsiao1260/segment-viewer",children:"Segment viewer"}),". Used by the segmentation team primarily to see which segments they have worked on already. Hosted ",(0,t.jsx)(n.a,{href:"http://37.19.207.113:5173/?mode=segment&segment=20230702185753",children:"here"})," By Yao Hsiao and Dalufishe"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-fragment-based-ink-detection",children:"\ud83d\udcdc Fragment-based Ink Detection"}),"\n",(0,t.jsx)(n.h4,{id:"-highlighted-5",children:"\ud83c\udf1f Highlighted"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/overview",children:"Kaggle competition on Fragments"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417496",children:"1st place"})," by Ryan Chesler"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417255",children:"2nd place"})," by RTX2309"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417536",children:"3rd place"})," by wuyu"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417779",children:"4th place"})," by POSCO DX -- Heeyoung Ahn"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417642",children:"5th place"})," by Aksell"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417274",children:"6th place"})," by chumajin"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417430",children:"7th place"})," by OverthINKingSegmenter"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417383",children:"8th place"})," by Luck is all you need"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417361",children:"9th place"})," by still 1 fold, 2 net"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/competitions/vesuvius-challenge-ink-detection/discussion/417363",children:"10th place"})," by Feng Qilong"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-inference",children:"2.5D fragment segmentation (ink detection) baseline"})," by Ryosuke Tanaka"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/educelab/ink-id",children:"Ink ID"})," by Stephen Parsons"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://discord.com/channels/1079907749569237093/1279263442913591349/1279263442913591349",children:"Iterative Labeling on fragments"})," by Youssef Nader. Applying the iterative labeling approach of the GP winning team to improve ink detection on fragments hidden layers."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"-reports-2",children:"\ud83d\udcdd Reports"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/ainatersol/Vesuvius-InkDetection/blob/main/additional_findings.md",children:"Kaggle Challenge top ink detection model analysis"})," by Ryan Chesler"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/MIC-DKFZ/OverthINKingSegmenter/blob/master/vesuvius_followup_writeup.pdf",children:"Ink detection model resolution analysis"})," by Yannick Kirchhoff, Maximilian Rokuss and Benjamin Hamm"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"other",children:"Other"}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-tools-4",children:"\u2699\ufe0f Tools"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/JamesDarby345/VesuviusDataDownload",children:"Efficient Data Downloader"}),": scripts to efficiently download data with rclone, by James Darby"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/Paul-G2/VesuviusScrollAlignment",children:"Improving scroll alignment with image registration"})," Scripts and a report showing how image registration can improve the alignment of scroll volumes scanned at different energies and resolutions, by Paul Geiger"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-materials-3",children:"\ud83d\udce6 Materials"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://dl.ash2txt.org/community-uploads/waynewaynehello/",children:"CT scanning campfire scrolls"})," Ahron Wayne replicated the carbonization process of a papyrus scroll and scanned it with his personal CT scanner"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-reports-3",children:"\ud83d\udcdd Reports"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://uknowledge.uky.edu/cs_etds/138/",children:"Hard-Hearted Scrolls"}),", PhD Dissertation by Stephen Parsons"]}),"\n"]}),"\n",(0,t.jsx)(n.h1,{id:"contributions",children:"Contributions"}),"\n",(0,t.jsx)(n.p,{children:"If you want to contribute and add any resource please submit a PR! \ud83d\ude0a\ud83d\ude80"})]})}function d(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>r,x:()=>o});var i=s(6540);const t={},l=i.createContext(t);function r(e){const n=i.useContext(l);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),i.createElement(l.Provider,{value:n},e.children)}}}]);